# Daily Kafka Questions Database
# Categories: core-concepts, troubleshooting, configuration
# Difficulty: beginner, intermediate, advanced

# Core Concepts (10 questions)
- id: 1
  category: "core-concepts"
  difficulty: "beginner"
  question: "What is the default retention period for Kafka topics?"
  options:
    - "24 hours"
    - "7 days"
    - "30 days"
    - "Forever"
  correct: 1
  explanation: "The default retention period is 7 days (168 hours), configured via log.retention.hours. After this period, messages are eligible for deletion."
  docs_link: "https://kafka.apache.org/documentation/#brokerconfigs_log.retention.hours"

- id: 2
  category: "core-concepts"
  difficulty: "beginner"
  question: "What uniquely identifies a message within a Kafka partition?"
  options:
    - "Message ID"
    - "Offset"
    - "Timestamp"
    - "Key hash"
  correct: 1
  explanation: "The offset is a sequential, immutable number assigned to each message within a partition. It uniquely identifies the message's position in the partition log."
  docs_link: "https://kafka.apache.org/documentation/#intro_concepts_and_terms"

- id: 3
  category: "core-concepts"
  difficulty: "intermediate"
  question: "What happens when a consumer group has more consumers than partitions?"
  options:
    - "Messages are duplicated across consumers"
    - "Some consumers remain idle"
    - "Kafka throws an error"
    - "Partitions are automatically created"
  correct: 1
  explanation: "Each partition can only be assigned to one consumer within a group. If there are more consumers than partitions, some consumers will be idle and not receive any messages."
  docs_link: "https://kafka.apache.org/documentation/#intro_consumers"

- id: 4
  category: "core-concepts"
  difficulty: "beginner"
  question: "What is the minimum number of in-sync replicas needed for a producer with acks=all to succeed?"
  options:
    - "All replicas"
    - "min.insync.replicas"
    - "Just the leader"
    - "Majority of replicas"
  correct: 1
  explanation: "With acks=all, the producer waits for acknowledgment from all in-sync replicas (ISR). The min.insync.replicas setting defines the minimum ISR count required for writes to succeed."
  docs_link: "https://kafka.apache.org/documentation/#brokerconfigs_min.insync.replicas"

- id: 5
  category: "core-concepts"
  difficulty: "intermediate"
  question: "How does Kafka guarantee message ordering?"
  options:
    - "Globally across all partitions"
    - "Within a single partition only"
    - "Based on message timestamps"
    - "Using distributed locks"
  correct: 1
  explanation: "Kafka only guarantees message ordering within a single partition. Messages with the same key are sent to the same partition, ensuring ordering for related messages."
  docs_link: "https://kafka.apache.org/documentation/#semantics"

- id: 6
  category: "core-concepts"
  difficulty: "beginner"
  question: "What is a Kafka consumer group?"
  options:
    - "A set of topics consumed together"
    - "Multiple consumers sharing partition assignments"
    - "Brokers that serve the same topic"
    - "A backup of consumer offsets"
  correct: 1
  explanation: "A consumer group is a set of consumers that work together to consume messages from a topic. Partitions are distributed among group members for parallel processing."
  docs_link: "https://kafka.apache.org/documentation/#intro_consumers"

- id: 7
  category: "core-concepts"
  difficulty: "advanced"
  question: "What is the role of the Controller in a Kafka cluster?"
  options:
    - "Handle all client requests"
    - "Manage partition leadership and cluster metadata"
    - "Store consumer offsets"
    - "Compress messages"
  correct: 1
  explanation: "The Controller is a broker elected to manage partition leader elections, handle broker failures, and maintain cluster metadata like partition assignments."
  docs_link: "https://kafka.apache.org/documentation/#design_replicamanagement"

- id: 8
  category: "core-concepts"
  difficulty: "intermediate"
  question: "What is the purpose of the __consumer_offsets topic?"
  options:
    - "Store message data"
    - "Track consumer group committed offsets"
    - "Log broker health metrics"
    - "Store topic configurations"
  correct: 1
  explanation: "The __consumer_offsets internal topic stores committed offsets for all consumer groups. This allows consumers to resume from their last position after restarts."
  docs_link: "https://kafka.apache.org/documentation/#impl_offsettracking"

- id: 9
  category: "core-concepts"
  difficulty: "beginner"
  question: "What is a Kafka broker?"
  options:
    - "A client that produces messages"
    - "A server that stores and serves messages"
    - "A tool for monitoring Kafka"
    - "A message compression algorithm"
  correct: 1
  explanation: "A Kafka broker is a server that receives messages from producers, stores them on disk, and serves them to consumers. A Kafka cluster consists of multiple brokers."
  docs_link: "https://kafka.apache.org/documentation/#introduction"

- id: 10
  category: "core-concepts"
  difficulty: "advanced"
  question: "What is KRaft mode in Kafka?"
  options:
    - "A compression algorithm"
    - "Kafka's built-in consensus without ZooKeeper"
    - "A replication strategy"
    - "A consumer protocol"
  correct: 1
  explanation: "KRaft (Kafka Raft) is Kafka's built-in consensus protocol that eliminates the need for ZooKeeper. It uses the Raft algorithm for metadata management and controller election."
  docs_link: "https://kafka.apache.org/documentation/#kraft"

# Troubleshooting (10 questions)
- id: 11
  category: "troubleshooting"
  difficulty: "intermediate"
  question: "What happens if a Kafka broker goes down?"
  options:
    - "All messages are lost"
    - "Leaders are elected on other brokers for its partitions"
    - "The entire cluster stops"
    - "Producers automatically retry indefinitely"
  correct: 1
  explanation: "When a broker fails, the Controller elects new leaders from the ISR for partitions that had leaders on the failed broker. With proper replication, no data is lost."
  docs_link: "https://kafka.apache.org/documentation/#design_replicamanagement"

- id: 12
  category: "troubleshooting"
  difficulty: "intermediate"
  question: "What is the most common cause of consumer lag?"
  options:
    - "Network latency"
    - "Slow message processing in the consumer"
    - "Too many partitions"
    - "Message compression"
  correct: 1
  explanation: "Consumer lag typically occurs when the consumer's message processing rate is slower than the producer's publish rate. This can be due to slow business logic, external I/O, or insufficient consumer parallelism."
  docs_link: "https://kafka.apache.org/documentation/#consumer_monitoring"

- id: 13
  category: "troubleshooting"
  difficulty: "advanced"
  question: "What causes a 'rebalancing storm' in Kafka consumers?"
  options:
    - "Too many messages"
    - "Consumers timing out during long processing"
    - "Network bandwidth limits"
    - "Disk space issues"
  correct: 1
  explanation: "Rebalancing storms occur when consumers exceed max.poll.interval.ms during processing, causing them to be removed from the group. This triggers rebalancing, which can cascade if the problem persists."
  docs_link: "https://kafka.apache.org/documentation/#consumerconfigs_max.poll.interval.ms"

- id: 14
  category: "troubleshooting"
  difficulty: "intermediate"
  question: "What does 'under-replicated partitions' indicate?"
  options:
    - "Too many consumers"
    - "Some replicas are not in sync with the leader"
    - "Topics have too few partitions"
    - "Message size is too large"
  correct: 1
  explanation: "Under-replicated partitions occur when follower replicas fall behind the leader and are removed from the ISR. This can be caused by broker failures, network issues, or disk problems."
  docs_link: "https://kafka.apache.org/documentation/#basic_ops_cluster_expansion"

- id: 15
  category: "troubleshooting"
  difficulty: "beginner"
  question: "What happens if a consumer crashes mid-processing before committing?"
  options:
    - "Message is lost forever"
    - "Message will be redelivered on next poll"
    - "Other consumers are notified"
    - "Producer resends the message"
  correct: 1
  explanation: "If a consumer crashes before committing its offset, the message will be redelivered to the consumer (or another consumer in the group) on the next poll. This is at-least-once delivery semantics."
  docs_link: "https://kafka.apache.org/documentation/#semantics"

- id: 16
  category: "troubleshooting"
  difficulty: "advanced"
  question: "What can cause 'LEADER_NOT_AVAILABLE' errors?"
  options:
    - "Consumer group is full"
    - "Partition leader election in progress"
    - "Message is too large"
    - "Invalid topic name"
  correct: 1
  explanation: "LEADER_NOT_AVAILABLE occurs when there's no leader for a partition, typically during leader election after a broker failure or when a topic is being created."
  docs_link: "https://kafka.apache.org/documentation/#design_replicamanagement"

- id: 17
  category: "troubleshooting"
  difficulty: "intermediate"
  question: "Why might a producer receive 'RecordTooLargeException'?"
  options:
    - "Too many partitions"
    - "Message exceeds max.message.bytes"
    - "Topic doesn't exist"
    - "Producer buffer is full"
  correct: 1
  explanation: "RecordTooLargeException occurs when a message exceeds the size limits set by message.max.bytes (broker) or max.message.bytes (topic). Default is 1MB."
  docs_link: "https://kafka.apache.org/documentation/#brokerconfigs_message.max.bytes"

- id: 18
  category: "troubleshooting"
  difficulty: "beginner"
  question: "What should you check first when consumers aren't receiving messages?"
  options:
    - "Message compression settings"
    - "Consumer group ID and topic subscription"
    - "Broker disk space"
    - "Producer batch size"
  correct: 1
  explanation: "When consumers aren't receiving messages, first verify the consumer group ID is correct and the consumer is subscribed to the right topics. Also check if offsets are positioned correctly."
  docs_link: "https://kafka.apache.org/documentation/#consumerconfigs"

- id: 19
  category: "troubleshooting"
  difficulty: "advanced"
  question: "What does 'OffsetOutOfRangeException' typically indicate?"
  options:
    - "Consumer lag is too high"
    - "Requested offset no longer exists on broker"
    - "Partition count changed"
    - "Consumer group rebalancing"
  correct: 1
  explanation: "OffsetOutOfRangeException occurs when a consumer requests an offset that no longer exists, usually because messages were deleted due to retention policies. The consumer needs to reset its offset."
  docs_link: "https://kafka.apache.org/documentation/#consumerconfigs_auto.offset.reset"

- id: 20
  category: "troubleshooting"
  difficulty: "intermediate"
  question: "How can you diagnose high producer latency?"
  options:
    - "Check consumer lag"
    - "Monitor batch.size and linger.ms settings"
    - "Increase partition count"
    - "Reduce replication factor"
  correct: 1
  explanation: "High producer latency can be caused by batching settings. If linger.ms is too high, producers wait to fill batches. If batch.size is too large, it takes longer to fill. Also check acks settings and broker response times."
  docs_link: "https://kafka.apache.org/documentation/#producerconfigs"

# Configuration (10 questions)
- id: 21
  category: "configuration"
  difficulty: "beginner"
  question: "What does 'acks=all' mean for a Kafka producer?"
  options:
    - "No acknowledgment needed"
    - "Only leader acknowledgment"
    - "All in-sync replicas must acknowledge"
    - "All brokers must acknowledge"
  correct: 2
  explanation: "With acks=all (or acks=-1), the producer waits for all in-sync replicas to acknowledge the message. This provides the strongest durability guarantee but highest latency."
  docs_link: "https://kafka.apache.org/documentation/#producerconfigs_acks"

- id: 22
  category: "configuration"
  difficulty: "intermediate"
  question: "What is the purpose of 'max.poll.records' consumer config?"
  options:
    - "Maximum messages in a topic"
    - "Maximum messages returned per poll()"
    - "Maximum consumer group size"
    - "Maximum message size"
  correct: 1
  explanation: "max.poll.records limits the number of records returned in a single poll() call. Lower values help prevent consumer timeouts during slow processing."
  docs_link: "https://kafka.apache.org/documentation/#consumerconfigs_max.poll.records"

- id: 23
  category: "configuration"
  difficulty: "intermediate"
  question: "What does 'auto.offset.reset' control?"
  options:
    - "Automatic partition rebalancing"
    - "Where to start reading when no committed offset exists"
    - "Automatic topic creation"
    - "Consumer group cleanup"
  correct: 1
  explanation: "auto.offset.reset determines where the consumer starts reading when there's no initial offset or the current offset no longer exists. Values: 'earliest', 'latest', or 'none'."
  docs_link: "https://kafka.apache.org/documentation/#consumerconfigs_auto.offset.reset"

- id: 24
  category: "configuration"
  difficulty: "advanced"
  question: "What is the recommended 'replication.factor' for production?"
  options:
    - "1"
    - "2"
    - "3"
    - "5"
  correct: 2
  explanation: "A replication factor of 3 is recommended for production. This allows the cluster to tolerate 1 broker failure while maintaining full ISR, and 2 failures while still having data available."
  docs_link: "https://kafka.apache.org/documentation/#replication"

- id: 25
  category: "configuration"
  difficulty: "beginner"
  question: "What is the default number of partitions for a new topic?"
  options:
    - "1"
    - "3"
    - "6"
    - "12"
  correct: 0
  explanation: "By default, new topics are created with 1 partition (num.partitions=1). This should typically be increased based on throughput requirements and consumer parallelism needs."
  docs_link: "https://kafka.apache.org/documentation/#brokerconfigs_num.partitions"

- id: 26
  category: "configuration"
  difficulty: "intermediate"
  question: "What does 'cleanup.policy=compact' do?"
  options:
    - "Compress messages"
    - "Keep only the latest value per key"
    - "Delete old messages faster"
    - "Reduce partition count"
  correct: 1
  explanation: "Log compaction keeps only the most recent value for each message key, effectively providing a changelog where the topic represents the latest state of each key."
  docs_link: "https://kafka.apache.org/documentation/#compaction"

- id: 27
  category: "configuration"
  difficulty: "advanced"
  question: "What is the purpose of 'unclean.leader.election.enable'?"
  options:
    - "Enable automatic topic creation"
    - "Allow out-of-sync replicas to become leaders"
    - "Enable consumer group auto-creation"
    - "Allow producers without authentication"
  correct: 1
  explanation: "When set to true, allows replicas not in ISR to become leaders during failures. This prevents unavailability but risks data loss. Default is false for safety."
  docs_link: "https://kafka.apache.org/documentation/#brokerconfigs_unclean.leader.election.enable"

- id: 28
  category: "configuration"
  difficulty: "intermediate"
  question: "What does 'enable.auto.commit=true' do for consumers?"
  options:
    - "Automatically creates topics"
    - "Periodically commits offsets in the background"
    - "Automatically rebalances partitions"
    - "Auto-scales consumer instances"
  correct: 1
  explanation: "With enable.auto.commit=true, the consumer automatically commits offsets at intervals defined by auto.commit.interval.ms. This simplifies code but may lead to at-least-once processing."
  docs_link: "https://kafka.apache.org/documentation/#consumerconfigs_enable.auto.commit"

- id: 29
  category: "configuration"
  difficulty: "beginner"
  question: "What is the purpose of 'bootstrap.servers' config?"
  options:
    - "Define topic settings"
    - "Initial brokers to connect and discover cluster"
    - "Set consumer starting position"
    - "Configure replication"
  correct: 1
  explanation: "bootstrap.servers is a list of host:port pairs for initial connection. The client uses these to discover the full cluster. Not all brokers need to be listed, just enough for initial contact."
  docs_link: "https://kafka.apache.org/documentation/#producerconfigs_bootstrap.servers"

- id: 30
  category: "configuration"
  difficulty: "advanced"
  question: "What does 'isolation.level=read_committed' mean for consumers?"
  options:
    - "Use SSL for connections"
    - "Only read non-transactional or committed transactional messages"
    - "Isolate consumer from other groups"
    - "Prevent rebalancing"
  correct: 1
  explanation: "With read_committed, consumers only see messages from committed transactions and non-transactional messages. This is essential for exactly-once semantics with transactional producers."
  docs_link: "https://kafka.apache.org/documentation/#consumerconfigs_isolation.level"

# KRaft Controller Quorum Questions (3)
- id: 31
  type: "diagram"
  category: "kraft-architecture"
  difficulty: "intermediate"
  question: "Click on the active controller in this KRaft quorum"
  diagram:
    type: "kraft-quorum"
    nodes:
      - { id: "c1", label: "Controller 1", role: "follower" }
      - { id: "c2", label: "Controller 2", role: "leader" }
      - { id: "c3", label: "Controller 3", role: "follower" }
  correct: "c2"
  explanation: "In a KRaft quorum, the active controller is the Raft leader (marked with a star). It handles all metadata updates and replicates changes to follower controllers. Controller 2 is the leader as indicated by the star icon."
  docs_link: "https://kafka.apache.org/documentation/#kraft"

- id: 32
  type: "diagram"
  category: "kraft-architecture"
  difficulty: "advanced"
  question: "Based on the epoch numbers, which controller will win the next election?"
  diagram:
    type: "kraft-quorum"
    nodes:
      - { id: "c1", label: "Controller 1", role: "follower", epoch: 5 }
      - { id: "c2", label: "Controller 2", role: "follower", epoch: 7 }
      - { id: "c3", label: "Controller 3", role: "follower", epoch: 6 }
  correct: "c2"
  explanation: "In Raft consensus, the controller with the highest epoch (term) and most up-to-date log wins elections. Controller 2 has epoch 7, which is the highest, so it will win the next leader election."
  docs_link: "https://kafka.apache.org/documentation/#kraft"

- id: 33
  type: "diagram"
  category: "kraft-architecture"
  difficulty: "intermediate"
  question: "Arrange the controller roles in the correct order of the metadata replication flow"
  diagram:
    type: "drag-topology"
    interaction: "drag"
    items:
      - { id: "leader", label: "Leader" }
      - { id: "follower1", label: "Follower 1" }
      - { id: "follower2", label: "Follower 2" }
    zones:
      - { id: "source", label: "Writes To" }
      - { id: "replica1", label: "Replicates From" }
      - { id: "replica2", label: "Replicates From" }
  correct:
    source: "leader"
    replica1: "follower1"
    replica2: "follower2"
  explanation: "In KRaft, the leader controller receives all metadata writes and replicates them to follower controllers. Followers fetch updates from the leader to stay in sync with the metadata log."
  docs_link: "https://kafka.apache.org/documentation/#kraft"

# Replication & ISR Questions (3)
- id: 34
  type: "diagram"
  category: "replication"
  difficulty: "intermediate"
  question: "Select all replicas that are currently in the ISR (In-Sync Replicas)"
  diagram:
    type: "partition-replicas"
    multi_select: true
    replicas:
      - { id: "r1", label: "Broker 1 - P0", role: "leader", offset: 1000, in_sync: true }
      - { id: "r2", label: "Broker 2 - P0", role: "follower", offset: 998, in_sync: true }
      - { id: "r3", label: "Broker 3 - P0", role: "follower", offset: 850, in_sync: false }
  correct:
    - "r1"
    - "r2"
  explanation: "ISR (In-Sync Replicas) includes the leader and all followers that are caught up within the replica.lag.time.max.ms threshold. Broker 3 is lagging significantly (offset 850 vs leader's 1000) and has been removed from ISR, as indicated by the LAG marker."
  docs_link: "https://kafka.apache.org/documentation/#replication"

- id: 35
  type: "diagram"
  category: "replication"
  difficulty: "beginner"
  question: "Click on the broker that is the leader for partition P0"
  diagram:
    type: "broker-cluster"
    brokers:
      - { id: "b1", label: "Broker 1" }
      - { id: "b2", label: "Broker 2" }
      - { id: "b3", label: "Broker 3" }
      - { id: "b4", label: "Broker 4" }
    partitions:
      - { broker: "b1", name: "P0", role: "leader" }
      - { broker: "b1", name: "P1", role: "follower" }
      - { broker: "b2", name: "P0", role: "follower" }
      - { broker: "b2", name: "P2", role: "leader" }
      - { broker: "b3", name: "P1", role: "leader" }
      - { broker: "b3", name: "P0", role: "follower" }
      - { broker: "b4", name: "P2", role: "follower" }
  correct: "b1"
  explanation: "Broker 1 hosts the leader replica for partition P0 (shown in orange/gold color). Leaders handle all produce and consume requests for a partition, while followers replicate data from the leader."
  docs_link: "https://kafka.apache.org/documentation/#replication"

- id: 36
  type: "diagram"
  category: "replication"
  difficulty: "advanced"
  question: "Arrange the replicas to show the correct data fetch direction (followers fetch from leader)"
  diagram:
    type: "drag-topology"
    interaction: "drag"
    items:
      - { id: "leader", label: "P0 Leader" }
      - { id: "follower1", label: "P0 Replica 1" }
      - { id: "follower2", label: "P0 Replica 2" }
    zones:
      - { id: "primary", label: "Source (Producers write here)" }
      - { id: "fetch1", label: "Fetches from Source" }
      - { id: "fetch2", label: "Fetches from Source" }
  correct:
    primary: "leader"
    fetch1: "follower1"
    fetch2: "follower2"
  explanation: "In Kafka replication, follower replicas fetch data from the leader. Producers only write to the leader, and followers pull the data to stay in sync. This is a pull-based replication model."
  docs_link: "https://kafka.apache.org/documentation/#replication"

# Fault Diagnosis Questions (2)
- id: 37
  type: "diagram"
  category: "fault-diagnosis"
  difficulty: "intermediate"
  question: "Based on the heartbeat timeline, click on the broker that will be fenced"
  diagram:
    type: "heartbeat-timeline"
    time_points: 6
    timeout: 3
    brokers:
      - { id: "b1", label: "Broker 1", heartbeats: [0, 1, 2, 3, 4, 5] }
      - { id: "b2", label: "Broker 2", heartbeats: [0, 1, 2] }
      - { id: "b3", label: "Broker 3", heartbeats: [0, 1, 2, 3, 4, 5] }
  correct: "b2"
  explanation: "Broker 2 stopped sending heartbeats after t2, missing 3 consecutive heartbeats (t3, t4, t5). Since the timeout threshold is 3 missed heartbeats, Broker 2 will be fenced by the controller and removed from the cluster until it recovers."
  docs_link: "https://kafka.apache.org/documentation/#brokerconfigs_broker.heartbeat.interval.ms"

- id: 38
  type: "diagram"
  category: "fault-diagnosis"
  difficulty: "advanced"
  question: "After Broker 3 fails, select all partitions that become under-replicated"
  diagram:
    type: "broker-cluster"
    multi_select: true
    brokers:
      - { id: "b1", label: "Broker 1" }
      - { id: "b2", label: "Broker 2" }
      - { id: "b3", label: "Broker 3", fenced: true }
    partitions:
      - { broker: "b1", name: "P0", role: "leader" }
      - { broker: "b1", name: "P2", role: "follower" }
      - { broker: "b2", name: "P1", role: "leader" }
      - { broker: "b2", name: "P0", role: "follower" }
      - { broker: "b3", name: "P0", role: "follower" }
      - { broker: "b3", name: "P1", role: "follower" }
      - { broker: "b3", name: "P2", role: "leader" }
  correct:
    - "b1"
    - "b2"
  explanation: "When Broker 3 fails, partitions P0, P1, and P2 all lose one replica. P0 and P1 remain available (leaders on B1 and B2) but are under-replicated. P2's leader was on B3, so it needs a new leader election from remaining ISR members. Brokers 1 and 2 now host all the remaining replicas of affected partitions."
  docs_link: "https://kafka.apache.org/documentation/#basic_ops_cluster_expansion"

# Consumer & Partition Assignment
- id: 39
  type: "diagram"
  category: "replication"
  difficulty: "intermediate"
  question: "Which replica will become the new leader if the current leader (Broker 1) fails?"
  diagram:
    type: "partition-replicas"
    replicas:
      - { id: "r1", label: "Broker 1 - P0", role: "leader", offset: 5000, in_sync: true }
      - { id: "r2", label: "Broker 2 - P0", role: "follower", offset: 4998, in_sync: true }
      - { id: "r3", label: "Broker 3 - P0", role: "follower", offset: 4200, in_sync: false }
  correct: "r2"
  explanation: "When the leader fails, Kafka elects a new leader from the ISR (In-Sync Replicas). Broker 2 is in the ISR (offset 4998, close to leader's 5000), while Broker 3 is lagging and not in ISR. Therefore, Broker 2 will become the new leader."
  docs_link: "https://kafka.apache.org/documentation/#design_replicamanagement"

- id: 40
  type: "diagram"
  category: "kraft-architecture"
  difficulty: "advanced"
  question: "Arrange the metadata update flow in KRaft mode"
  diagram:
    type: "drag-topology"
    interaction: "drag"
    items:
      - { id: "client", label: "Admin Client" }
      - { id: "controller", label: "Active Controller" }
      - { id: "broker", label: "Broker" }
    zones:
      - { id: "step1", label: "1. Sends Request" }
      - { id: "step2", label: "2. Commits to Log" }
      - { id: "step3", label: "3. Fetches Update" }
  correct:
    step1: "client"
    step2: "controller"
    step3: "broker"
  explanation: "In KRaft mode, admin requests (like topic creation) go to the active controller, which commits changes to the metadata log. Brokers then fetch these metadata updates from the controller to stay in sync."
  docs_link: "https://kafka.apache.org/documentation/#kraft"

- id: 41
  type: "diagram"
  category: "fault-diagnosis"
  difficulty: "intermediate"
  question: "Based on the heartbeat timeline, which broker is experiencing network issues?"
  diagram:
    type: "heartbeat-timeline"
    time_points: 8
    timeout: 3
    brokers:
      - { id: "b1", label: "Broker 1", heartbeats: [0, 1, 2, 3, 4, 5, 6, 7] }
      - { id: "b2", label: "Broker 2", heartbeats: [0, 1, 3, 4, 6, 7] }
      - { id: "b3", label: "Broker 3", heartbeats: [0, 1, 2, 3, 4, 5, 6, 7] }
  correct: "b2"
  explanation: "Broker 2 has intermittent heartbeat failures (missing t2 and t5), indicating network instability. While not enough consecutive misses to trigger fencing (threshold is 3), this pattern suggests network issues that should be investigated."
  docs_link: "https://kafka.apache.org/documentation/#brokerconfigs_broker.heartbeat.interval.ms"

- id: 42
  type: "diagram"
  category: "replication"
  difficulty: "advanced"
  question: "Select all replicas that should receive the next batch of messages from the producer"
  diagram:
    type: "partition-replicas"
    multi_select: true
    replicas:
      - { id: "r1", label: "Broker 1 - P0", role: "leader", offset: 1000, in_sync: true }
      - { id: "r2", label: "Broker 2 - P0", role: "follower", offset: 999, in_sync: true }
      - { id: "r3", label: "Broker 3 - P0", role: "follower", offset: 998, in_sync: true }
      - { id: "r4", label: "Broker 4 - P0", role: "follower", offset: 500, in_sync: false }
  correct:
    - "r1"
  explanation: "Producers only send messages to the partition leader (Broker 1). Followers fetch data from the leader - they don't receive directly from producers. With acks=all, the leader waits for ISR followers to replicate before acknowledging, but the producer only communicates with the leader."
  docs_link: "https://kafka.apache.org/documentation/#replication"

- id: 43
  type: "diagram"
  category: "kraft-architecture"
  difficulty: "beginner"
  question: "Click on the controller that voters will contact to join the quorum"
  diagram:
    type: "kraft-quorum"
    nodes:
      - { id: "c1", label: "Controller 1", role: "follower" }
      - { id: "c2", label: "Controller 2", role: "leader" }
      - { id: "c3", label: "Controller 3", role: "follower" }
  correct: "c2"
  explanation: "New voters and brokers contact the active controller (the Raft leader) to register and join the cluster. The leader handles all write operations including voter registration."
  docs_link: "https://kafka.apache.org/documentation/#kraft"

- id: 44
  type: "diagram"
  category: "fault-diagnosis"
  difficulty: "advanced"
  question: "After the leader on Broker 2 fails, click on the broker that will become the new leader for P1"
  diagram:
    type: "broker-cluster"
    brokers:
      - { id: "b1", label: "Broker 1" }
      - { id: "b2", label: "Broker 2", fenced: true }
      - { id: "b3", label: "Broker 3" }
      - { id: "b4", label: "Broker 4" }
    partitions:
      - { broker: "b1", name: "P0", role: "leader" }
      - { broker: "b1", name: "P1", role: "follower" }
      - { broker: "b2", name: "P1", role: "leader" }
      - { broker: "b2", name: "P2", role: "follower" }
      - { broker: "b3", name: "P2", role: "leader" }
      - { broker: "b3", name: "P0", role: "follower" }
      - { broker: "b4", name: "P1", role: "follower" }
      - { broker: "b4", name: "P0", role: "follower" }
  correct: "b1"
  explanation: "When Broker 2 (P1's leader) fails, Kafka elects a new leader from ISR. Broker 1 is listed first in the replica list for P1, making it the preferred leader. Following the preferred replica order, Broker 1 becomes the new leader for P1."
  docs_link: "https://kafka.apache.org/documentation/#basic_ops_leader_balancing"

- id: 45
  type: "diagram"
  category: "replication"
  difficulty: "intermediate"
  question: "Arrange the message acknowledgment flow for acks=all"
  diagram:
    type: "drag-topology"
    interaction: "drag"
    items:
      - { id: "producer", label: "Producer" }
      - { id: "leader", label: "Leader Replica" }
      - { id: "followers", label: "ISR Followers" }
    zones:
      - { id: "send", label: "1. Sends Message" }
      - { id: "replicate", label: "2. Replicates To" }
      - { id: "ack", label: "3. Acknowledges" }
  correct:
    send: "producer"
    replicate: "leader"
    ack: "followers"
  explanation: "With acks=all: (1) Producer sends to leader, (2) Leader writes and replicates to ISR followers, (3) After all ISR followers acknowledge to the leader, the leader sends final ack to producer. This ensures durability across all in-sync replicas."
  docs_link: "https://kafka.apache.org/documentation/#producerconfigs_acks"

- id: 46
  type: "diagram"
  category: "fault-diagnosis"
  difficulty: "intermediate"
  question: "Select all brokers that are healthy and fully operational"
  diagram:
    type: "broker-cluster"
    multi_select: true
    brokers:
      - { id: "b1", label: "Broker 1" }
      - { id: "b2", label: "Broker 2", fenced: true }
      - { id: "b3", label: "Broker 3" }
      - { id: "b4", label: "Broker 4", fenced: true }
    partitions:
      - { broker: "b1", name: "P0", role: "leader" }
      - { broker: "b1", name: "P1", role: "follower" }
      - { broker: "b2", name: "P1", role: "leader" }
      - { broker: "b3", name: "P2", role: "leader" }
      - { broker: "b3", name: "P0", role: "follower" }
      - { broker: "b4", name: "P2", role: "follower" }
  correct:
    - "b1"
    - "b3"
  explanation: "Brokers 1 and 3 are healthy (not fenced). Brokers 2 and 4 are fenced, meaning they've been removed from the cluster due to missed heartbeats or other failures. Fenced brokers cannot serve client requests."
  docs_link: "https://kafka.apache.org/documentation/#kraft"

- id: 47
  type: "diagram"
  category: "kraft-architecture"
  difficulty: "advanced"
  question: "In this quorum, which controller has the most up-to-date log?"
  diagram:
    type: "kraft-quorum"
    nodes:
      - { id: "c1", label: "Controller 1", role: "follower", epoch: 3 }
      - { id: "c2", label: "Controller 2", role: "follower", epoch: 3 }
      - { id: "c3", label: "Controller 3", role: "follower", epoch: 4 }
  correct: "c3"
  explanation: "Controller 3 has the highest epoch (4), indicating it has seen the most recent leader term. In Raft, higher epoch means more recent leadership term, so Controller 3 has the most up-to-date metadata log."
  docs_link: "https://kafka.apache.org/documentation/#kraft"

- id: 48
  type: "diagram"
  category: "replication"
  difficulty: "beginner"
  question: "Click on the replica that is falling behind and may soon be removed from ISR"
  diagram:
    type: "partition-replicas"
    replicas:
      - { id: "r1", label: "Broker 1 - P0", role: "leader", offset: 10000, in_sync: true }
      - { id: "r2", label: "Broker 2 - P0", role: "follower", offset: 9998, in_sync: true }
      - { id: "r3", label: "Broker 3 - P0", role: "follower", offset: 9200, in_sync: true }
  correct: "r3"
  explanation: "Broker 3's replica is 800 messages behind the leader (offset 9200 vs 10000), while Broker 2 is only 2 behind. If Broker 3 doesn't catch up within replica.lag.time.max.ms, it will be removed from ISR."
  docs_link: "https://kafka.apache.org/documentation/#brokerconfigs_replica.lag.time.max.ms"
